{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1647d6-6e25-41fe-84e9-8c8e934c8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b3a4b3-4e77-4e5e-a75e-1dfd6cabeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    "tokens=word_tokenize(document)\n",
    "pos_tags=pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6cb6b4-82d5-4284-a24b-56d72c7a1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "filtered_tokens=[word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058cee5b-bca6-40c2-9350-28510605f34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "pos_tags: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), (',', ','), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('information', 'NN'), ('engineering', 'NN'), (',', ','), ('and', 'CC'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('concerned', 'VBN'), ('with', 'IN'), ('the', 'DT'), ('interactions', 'NNS'), ('between', 'IN'), ('computers', 'NNS'), ('and', 'CC'), ('human', 'JJ'), ('(', '('), ('natural', 'JJ'), (')', ')'), ('languages', 'NNS'), (',', ','), ('in', 'IN'), ('particular', 'JJ'), ('how', 'WRB'), ('to', 'TO'), ('program', 'NN'), ('computers', 'NNS'), ('to', 'TO'), ('process', 'VB'), ('and', 'CC'), ('analyze', 'VB'), ('large', 'JJ'), ('amounts', 'NNS'), ('of', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('data', 'NNS'), ('.', '.')]\n",
      "stopwords: {'has', 'won', 'doing', 'had', 'didn', 'further', 're', 'what', 'now', 'no', 'out', \"you'd\", 'each', 'too', \"doesn't\", 'before', 'again', 's', 'themselves', 'our', 'doesn', \"didn't\", 'her', 'down', 'very', 'that', 'and', 'is', 'just', 'it', 'where', 'most', \"haven't\", 'hasn', 'they', 'over', 'been', 'a', \"don't\", 'all', 'about', 'both', 'll', 'him', 'of', 'having', 've', 'wouldn', 'their', 'these', \"needn't\", 'be', 'ours', 'such', 'yourself', 'under', 'should', 'than', 'this', 'my', 'ourselves', 'me', \"hadn't\", \"weren't\", 'with', 'y', 'ain', 'how', 'he', 'for', 'd', 'needn', \"you've\", 'yours', 'more', \"shan't\", 'up', 'any', 'those', 'by', 'while', 'himself', 'theirs', 'aren', 'your', \"wouldn't\", 'as', 'hadn', 'above', 'myself', 'do', 'on', 'there', 'same', \"won't\", 'during', 'o', 'i', 'isn', 'against', 'own', 'you', 'ma', 'can', \"mustn't\", \"mightn't\", 'the', 'mustn', \"you'll\", 'haven', 'don', \"you're\", 'then', 'whom', 'if', 'its', 'did', 'wasn', 'off', \"she's\", 'at', 'other', 'his', 'hers', \"couldn't\", 'are', 'through', \"isn't\", 'here', 'between', 'nor', 'was', 'so', 'have', 'were', 'does', \"it's\", 'because', 'she', \"shouldn't\", 'until', 'herself', 'itself', 'but', \"wasn't\", 'am', 'weren', 'in', 'into', 'shan', 'from', 'when', \"should've\", 'm', 'will', 'or', \"that'll\", 'few', 'couldn', \"aren't\", 'who', 'them', 'which', 'not', 'an', \"hasn't\", 'why', 'being', 'below', 'after', 't', 'once', 'to', 'only', 'shouldn', 'yourselves', 'mightn', 'we', 'some'}\n",
      "Porter stemmer: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'inform', 'engin', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "Snowball stemmer: ['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'inform', 'engin', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "Lancaster stemmer: ['nat', 'langu', 'process', '(', 'nlp', ')', 'subfield', 'lingu', ',', 'comput', 'sci', ',', 'inform', 'engin', ',', 'art', 'intellig', 'concern', 'interact', 'comput', 'hum', '(', 'nat', ')', 'langu', ',', 'particul', 'program', 'comput', 'process', 'analys', 'larg', 'amount', 'nat', 'langu', 'dat', '.']\n",
      "word net lemmatization: ['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', '(', 'natural', ')', 'language', ',', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "port_stemmer=PorterStemmer()\n",
    "snowball_stemmer=SnowballStemmer(\"english\")\n",
    "lancaster_stemmer=LancasterStemmer()\n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "stemmed_porter=[port_stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed_snowball=[snowball_stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed_lancaster=[lancaster_stemmer.stem(word) for word in filtered_tokens]\n",
    "lemmatized_tokens=[wordnet_lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "print(\"tokens:\",tokens)\n",
    "print(\"pos_tags:\",pos_tags)\n",
    "print(\"stopwords:\",stop_words)\n",
    "print(\"Porter stemmer:\",stemmed_porter)\n",
    "print(\"Snowball stemmer:\",stemmed_snowball)\n",
    "print(\"Lancaster stemmer:\",stemmed_lancaster)\n",
    "print(\"word net lemmatization:\",lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da758483-7ec3-4c86-8dd1-8d8c8d3b9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector=TfidfVectorizer()\n",
    "tfidf_matrix=tfidf_vector.fit_transform([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4663aa92-33bf-459d-a182-2f3f3c35af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f88f3b-7073-4404-b6c6-bee88d7a7f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    amounts   analyze       and  artificial   between  computer  computers  \\\n",
      "0  0.128037  0.128037  0.384111    0.128037  0.128037  0.128037   0.256074   \n",
      "\n",
      "   concerned      data  engineering  ...        of  particular   process  \\\n",
      "0   0.128037  0.128037     0.128037  ...  0.256074    0.128037  0.128037   \n",
      "\n",
      "   processing   program   science  subfield       the        to      with  \n",
      "0    0.128037  0.128037  0.128037  0.128037  0.128037  0.256074  0.128037  \n",
      "\n",
      "[1 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c840d015-7721-4e5c-a09b-7266cb18f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer,SnowballStemmer,LancasterStemmer,WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4790dfee-95b1-4059-ae7e-c4a204d19f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=\"Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    "tokens=word_tokenize(document)\n",
    "pos_tags=pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de8c498-41ed-4a79-9f13-385225da59be",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "filtered_tokens=[word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec05d1d-5384-4f48-847e-04767bbf6265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "<function pos_tag at 0x000001FC6E782DE0>\n",
      "{'has', 'won', 'doing', 'had', 'didn', 'further', 're', 'what', 'now', 'no', 'out', \"you'd\", 'each', 'too', \"doesn't\", 'before', 'again', 's', 'themselves', 'our', 'doesn', \"didn't\", 'her', 'down', 'very', 'that', 'and', 'is', 'just', 'it', 'where', 'most', \"haven't\", 'hasn', 'they', 'over', 'been', 'a', \"don't\", 'all', 'about', 'both', 'll', 'him', 'of', 'having', 've', 'wouldn', 'their', 'these', \"needn't\", 'be', 'ours', 'such', 'yourself', 'under', 'should', 'than', 'this', 'my', 'ourselves', 'me', \"hadn't\", \"weren't\", 'with', 'y', 'ain', 'how', 'he', 'for', 'd', 'needn', \"you've\", 'yours', 'more', \"shan't\", 'up', 'any', 'those', 'by', 'while', 'himself', 'theirs', 'aren', 'your', \"wouldn't\", 'as', 'hadn', 'above', 'myself', 'do', 'on', 'there', 'same', \"won't\", 'during', 'o', 'i', 'isn', 'against', 'own', 'you', 'ma', 'can', \"mustn't\", \"mightn't\", 'the', 'mustn', \"you'll\", 'haven', 'don', \"you're\", 'then', 'whom', 'if', 'its', 'did', 'wasn', 'off', \"she's\", 'at', 'other', 'his', 'hers', \"couldn't\", 'are', 'through', \"isn't\", 'here', 'between', 'nor', 'was', 'so', 'have', 'were', 'does', \"it's\", 'because', 'she', \"shouldn't\", 'until', 'herself', 'itself', 'but', \"wasn't\", 'am', 'weren', 'in', 'into', 'shan', 'from', 'when', \"should've\", 'm', 'will', 'or', \"that'll\", 'few', 'couldn', \"aren't\", 'who', 'them', 'which', 'not', 'an', \"hasn't\", 'why', 'being', 'below', 'after', 't', 'once', 'to', 'only', 'shouldn', 'yourselves', 'mightn', 'we', 'some'}\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', '(', 'natural', ')', 'languages', ',', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'data', '.']\n",
      "['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'inform', 'engin', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "['natur', 'languag', 'process', '(', 'nlp', ')', 'subfield', 'linguist', ',', 'comput', 'scienc', ',', 'inform', 'engin', ',', 'artifici', 'intellig', 'concern', 'interact', 'comput', 'human', '(', 'natur', ')', 'languag', ',', 'particular', 'program', 'comput', 'process', 'analyz', 'larg', 'amount', 'natur', 'languag', 'data', '.']\n",
      "['nat', 'langu', 'process', '(', 'nlp', ')', 'subfield', 'lingu', ',', 'comput', 'sci', ',', 'inform', 'engin', ',', 'art', 'intellig', 'concern', 'interact', 'comput', 'hum', '(', 'nat', ')', 'langu', ',', 'particul', 'program', 'comput', 'process', 'analys', 'larg', 'amount', 'nat', 'langu', 'dat', '.']\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'subfield', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', '(', 'natural', ')', 'language', ',', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "port_stemmer=PorterStemmer()\n",
    "snowball_stemmer=SnowballStemmer(\"english\")\n",
    "lancaster_stemmer=LancasterStemmer()\n",
    "wordnet_lemmatizer=WordNetLemmatizer()\n",
    "\n",
    "stemmed_porter=[port_stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed_snowball=[snowball_stemmer.stem(word) for word in filtered_tokens]\n",
    "stemmed_lancaster=[lancaster_stemmer.stem(word) for word in filtered_tokens]\n",
    "lemmatized_tokens=[wordnet_lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(tokens)\n",
    "print(pos_tag)\n",
    "print(stop_words)\n",
    "print(filtered_tokens)\n",
    "print(stemmed_porter)\n",
    "print(stemmed_snowball)\n",
    "print(stemmed_lancaster)\n",
    "print(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd5960d7-e93a-4eac-a9f1-12e7281dac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector=TfidfVectorizer()\n",
    "tfidf_matrix=tfidf_vector.fit_transform([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ee4e00d-dcd5-4c2d-9602-1918f069cfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    amounts   analyze       and  artificial   between  computer  computers  \\\n",
      "0  0.128037  0.128037  0.384111    0.128037  0.128037  0.128037   0.256074   \n",
      "\n",
      "   concerned      data  engineering  ...        of  particular   process  \\\n",
      "0   0.128037  0.128037     0.128037  ...  0.256074    0.128037  0.128037   \n",
      "\n",
      "   processing   program   science  subfield       the        to      with  \n",
      "0    0.128037  0.128037  0.128037  0.128037  0.128037  0.256074  0.128037  \n",
      "\n",
      "[1 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "tfidf_df=pd.DataFrame(tfidf_matrix.toarray(),columns=tfidf_vector.get_feature_names_out())\n",
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b4627-aebb-4ddf-8b00-dc1393ef33de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
